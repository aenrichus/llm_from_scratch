{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ea3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a4032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  POSITIVE  0.999473"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test installation of the transformers library\n",
    "from transformers import pipeline\n",
    "nlp = pipeline(\"sentiment-analysis\", framework=\"pt\")\n",
    "\n",
    "# Test the pipeline with a simple input\n",
    "text = (\"Every time Henry dives into the world of transformers, my heart leaps with \"\n",
    "        \"excitement—there’s something truly magical about how self-attention layers \"\n",
    "        \"dance together to capture the poetry of language! I absolutely love watching \"\n",
    "        \"those attention heads weave context across tokens, like tiny explorers \"\n",
    "        \"mapping out meaning in every sentence. Each experiment feels like a grand \"\n",
    "        \"adventure: tweaking learning rates, sculpting architectures, and fine-tuning \"\n",
    "        \"on fresh datasets sends waves of new insights crashing over me. It’s as if \"\n",
    "        \"the very act of training these models sparks a conversation between math, \"\n",
    "        \"code, and creativity, reminding me how boundless our capacity to learn and \"\n",
    "        \"innovate can be. With every epoch that passes, I find myself more in awe of \"\n",
    "        \"the elegant simplicity and profound power of transformers—my unwavering \"\n",
    "        \"companions on an endless journey of discovery!\"\n",
    ")\n",
    "outputs = nlp(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c655f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  POSITIVE  0.999473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text classification and sentiment analysis seem similar\n",
    "classifier = pipeline(\"text-classification\", framework=\"pt\")\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7559d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.998267</td>\n",
       "      <td>Henry</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score   word  start  end\n",
       "0          PER  0.998267  Henry     11   16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named entity recognition\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\", framework=\"pt\")\n",
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cfd8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.380045</td>\n",
       "      <td>218</td>\n",
       "      <td>276</td>\n",
       "      <td>watching those attention heads weave context a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                                             answer\n",
       "0  0.380045    218  276  watching those attention heads weave context a..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question answering\n",
    "reader = pipeline(\"question-answering\", framework=\"pt\")\n",
    "question = \"What do I love about transformers?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954edde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Each experiment feels like a grand adventure: tweaking learning rates, sculpting architectures, and fine-tuning on fresh datasets sends waves of new insights crashing over me. With each epoch that passes, I find myself more in awe of the\n"
     ]
    }
   ],
   "source": [
    "# Summarization\n",
    "summarizer = pipeline(\"summarization\", framework=\"pt\")\n",
    "outputs = summarizer(text, max_length=50, min_length=25, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8ea18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ヘンリーがトランスフォーマーの世界に潜むたびに,私の心は興奮に跳ね上がります. 言語の詩を捉えるために注意の層が一緒に踊る方法には,本当に魔法のようなものがあります!私は,それらの注意の頭がトークンを通して文脈を織りなすのを眺めることをとても好きです. 小さな探検家のように,それぞれの文に意味を映し出します.すべての実験は,偉大な冒険のように感じます.学習速度を調整し,建築を彫り上げ,新しいデータセットに細かく調整することで,新しい洞察の波が私の上に押し寄せます. これらのモデルを訓練する行為自体が,数学,コード,そして創造力との対話を引き起こし,私たちの学習と革新の能力がどれほど無限のかを思い出させるようなものです. 過ぎゆく時代ごとに,私は,無限の発見の旅で私の仲間たちの優雅なシンプルさと深刻な力にますます驚いています.\n"
     ]
    }
   ],
   "source": [
    "# Translation\n",
    "translator = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"jpn_Jpan\",\n",
    "    max_length=400,\n",
    "    framework=\"pt\"\n",
    "    )\n",
    "outputs = translator(text, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 116869.15it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 4310.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ヘンリーがトランスフォーマーの世界に潜るたびに 私の心は興奮で跳ね上がります! 言語の詩を捉えるために 自己注意の層がどのように一緒に踊っているかについて 本当に魔法のようなものがあります! 私はそれらの注意の頭がトークンを通して文脈を織りなすのを,小さな探検家のように,各文の意味を映し出すのを観るのが大好きです. それぞれの実験は壮大な冒険のように感じます. 学習率を調整し,アーキテクチャを彫り,新鮮なデータセットを細かく調整することで,新しい洞察の波が私の上に押し寄せます. これらのモデルを訓練する行為自体が数学,コード,創造性との間の会話を引き起こし,私たちの学習と革新の能力がどれほど無限であるかを思い出させます. 時代が経つにつれて,私はトランスフォーマーの優雅さと深い力にますます驚きます. 終わりのない発見の旅の私の揺るぎない仲間です!\n"
     ]
    }
   ],
   "source": [
    "# Translation (English to Japanese) using CTranslate2\n",
    "\n",
    "\"\"\"\n",
    "Fast EN → JA with CTranslate2-fast NLLB-1.3B\n",
    "-------------------------------------------\n",
    "• Model weights:  michaelfeil/ct2fast-nllb-200-distilled-1.3B\n",
    "• Vocab (SPM):    facebook/nllb-200-distilled-1.3B\n",
    "• Device: CPU (int8_float32) or change to \"cuda\" + \"int8_float16\"\n",
    "\"\"\"\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "import sentencepiece as spm\n",
    "import ctranslate2\n",
    "import pathlib\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Download & cache the model & tokenizer\n",
    "# ------------------------------------------------------------------\n",
    "MODEL_REPO = \"michaelfeil/ct2fast-nllb-200-distilled-1.3B\"\n",
    "model_dir  = snapshot_download(MODEL_REPO)  # ≈1.4 GB weights\n",
    "\n",
    "# The shared SPM vocab lives in Meta’s official NLLB-200 repo\n",
    "SPM_REPO   = \"facebook/nllb-200-distilled-1.3B\"\n",
    "spm_root   = snapshot_download(\n",
    "    SPM_REPO, allow_patterns=\"sentencepiece.bpe.model\")\n",
    "spm_file   = pathlib.Path(spm_root, \"sentencepiece.bpe.model\")\n",
    "\n",
    "# Load SentencePiece\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(str(spm_file))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Instantiate the Translator\n",
    "# ------------------------------------------------------------------\n",
    "device   = \"cpu\"  # or \"cuda\" if you’ve got an NVIDIA GPU\n",
    "compute  = \"int8_float32\" if device == \"cpu\" else \"int8_float16\"\n",
    "\n",
    "translator = ctranslate2.Translator(\n",
    "    model_dir,\n",
    "    device=device,\n",
    "    compute_type=compute\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) The translate() helper\n",
    "# ------------------------------------------------------------------\n",
    "def translate(\n",
    "    texts:list[str],\n",
    "    src: str = \"eng_Latn\",\n",
    "    tgt: str = \"jpn_Jpan\",\n",
    "    beam: int = 4\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    texts: English sentences\n",
    "    returns: Japanese sentences\n",
    "    \"\"\"\n",
    "    # 1) SPM-tokenise & add [SRC]…[\"</s>\"]\n",
    "    batches = [\n",
    "        [src] + sp.encode(t, out_type=str) + [\"</s>\"]\n",
    "        for t in texts\n",
    "    ]\n",
    "\n",
    "    # 2) Tell CT2 to seed decoding with [TGT]\n",
    "    tgt_prefix = [[tgt]] * len(batches)\n",
    "\n",
    "    # 3) Translate, batching by tokens\n",
    "    results = translator.translate_batch(\n",
    "        batches,\n",
    "        batch_type=\"tokens\",\n",
    "        max_batch_size=2048,\n",
    "        beam_size=beam,\n",
    "        target_prefix=tgt_prefix\n",
    "    )\n",
    "\n",
    "    # 4) Post-process & detokenise\n",
    "    outputs = []\n",
    "    for r in results:\n",
    "        hyp = r.hypotheses[0]\n",
    "\n",
    "        # strip out any leftover tags/EOS\n",
    "        hyp = [tok for tok in hyp if tok not in (tgt, \"</s>\")]\n",
    "\n",
    "        # decode pieces → string\n",
    "        outputs.append(sp.decode_pieces(hyp))\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) Smoke test\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # sample = [\"The quick brown fox jumps over the lazy dog.\"]\n",
    "    # Test the pipeline with a simple input\n",
    "    text = ([\"Every time Henry dives into the world of transformers, my heart leaps with \"\n",
    "            \"excitement—there’s something truly magical about how self-attention layers \"\n",
    "            \"dance together to capture the poetry of language! I absolutely love watching \"\n",
    "            \"those attention heads weave context across tokens, like tiny explorers \"\n",
    "            \"mapping out meaning in every sentence. Each experiment feels like a grand \"\n",
    "            \"adventure: tweaking learning rates, sculpting architectures, and fine-tuning \"\n",
    "            \"on fresh datasets sends waves of new insights crashing over me. It’s as if \"\n",
    "            \"the very act of training these models sparks a conversation between math, \"\n",
    "            \"code, and creativity, reminding me how boundless our capacity to learn and \"\n",
    "            \"innovate can be. With every epoch that passes, I find myself more in awe of \"\n",
    "            \"the elegant simplicity and profound power of transformers—my unwavering \"\n",
    "            \"companions on an endless journey of discovery!\"]\n",
    "    )\n",
    "    print(translate(text)[0])\n",
    "    # → 素早い茶色のキツネが怠け者の犬を飛び越えた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc8e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every time Henry dives into the world of transformers, my heart leaps\n",
      "with excitement—there’s something truly magical about how self-attention\n",
      "layers dance together to capture the poetry of language! I absolutely\n",
      "love watching those attention heads weave context across tokens, like\n",
      "tiny explorers mapping out meaning in every sentence. Each experiment\n",
      "feels like a grand adventure: tweaking learning rates, sculpting\n",
      "architectures, and fine-tuning on fresh datasets sends waves of new\n",
      "insights crashing over me. It’s as if the very act of training these\n",
      "models sparks a conversation between math, code, and creativity,\n",
      "reminding me how boundless our capacity to learn and innovate can be.\n",
      "With every epoch that passes, I find myself more in awe of the elegant\n",
      "simplicity and profound power of transformers—my unwavering companions\n",
      "on an endless journey of discovery!\n",
      "\n",
      "Response from an AI mentor, like Karpathy:\n",
      "\n",
      "Wow, Henry is so passionate about transformers!  I love the way he makes\n",
      "it clear that his passion is about what it means to be a human, and how\n",
      "many people can use it to get their own work done.\n",
      "\n",
      "I'm excited to hear more from him about this.  I think the fact that he\n",
      "knows more about the world of transformers is a nice touch, and I'm\n",
      "excited to see how his work will be applied to many other open source\n",
      "projects.\n",
      "\n",
      "Henry is an awesome person and a great person to work with.  I hope you\n",
      "think he is inspired enough to take an interest in his work.  What other\n",
      "people think of your work? How would you describe your work? Any\n",
      "additional comments or questions?\n",
      "\n",
      "Advertisements\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Function to wrap paragraphs\n",
    "def wrap_paragraphs(text, width=70):\n",
    "    paras = text.split(\"\\n\\n\")\n",
    "    return \"\\n\\n\".join(textwrap.fill(p, width=width) for p in paras)\n",
    "\n",
    "# Text generation\n",
    "generator = pipeline(\"text-generation\", framework=\"pt\")\n",
    "response = \"Wow, Henry is so passionate about transformers! \"\n",
    "prompt = text[0] + \"\\n\\nResponse from an AI mentor, like Karpathy:\\n\\n\" + response\n",
    "outputs = generator(prompt, max_length=200, truncation=True, clean_up_tokenization_spaces=True)\n",
    "wrapped_text = wrap_paragraphs(outputs[0]['generated_text'], width=72)\n",
    "print(wrapped_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_scratch_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
